{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d5fbfb0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in c:\\users\\user\\anaconda3\\lib\\site-packages (0.10.11)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\user\\anaconda3\\lib\\site-packages (4.8.1.78)\n",
      "Requirement already satisfied: absl-py in c:\\users\\user\\anaconda3\\lib\\site-packages (from mediapipe) (2.1.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from mediapipe) (23.1.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from mediapipe) (24.3.25)\n",
      "Requirement already satisfied: jax in c:\\users\\user\\anaconda3\\lib\\site-packages (from mediapipe) (0.4.26)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\user\\anaconda3\\lib\\site-packages (from mediapipe) (3.8.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (from mediapipe) (1.25.2)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\user\\anaconda3\\lib\\site-packages (from mediapipe) (4.9.0.80)\n",
      "Requirement already satisfied: protobuf<4,>=3.11 in c:\\users\\user\\anaconda3\\lib\\site-packages (from mediapipe) (3.20.3)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from mediapipe) (0.4.6)\n",
      "Requirement already satisfied: CFFI>=1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from sounddevice>=0.4.4->mediapipe) (1.15.1)\n",
      "Requirement already satisfied: ml-dtypes>=0.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jax->mediapipe) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum in c:\\users\\user\\anaconda3\\lib\\site-packages (from jax->mediapipe) (3.3.0)\n",
      "Requirement already satisfied: scipy>=1.9 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jax->mediapipe) (1.11.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (10.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (2.8.2)\n",
      "Requirement already satisfied: pycparser in c:\\users\\user\\anaconda3\\lib\\site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install mediapipe opencv-python\n",
    "\n",
    "import sys\n",
    "sys.version\n",
    "\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "030e9a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angle(a,b,c):\n",
    "    a = np.array(a) # First\n",
    "    b = np.array(b) # Mid\n",
    "    c = np.array(c) # End\n",
    "    \n",
    "    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "    angle = np.abs(radians*180.0/np.pi)\n",
    "    \n",
    "    if angle >180.0:\n",
    "        angle = 360-angle\n",
    "        \n",
    "    return round(angle) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f1c4bfb2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "재생할 파일 넓이, 높이 : 1920, 1080\n",
      "150\n",
      "139\n",
      "106\n",
      "91\n",
      "122\n",
      "145\n",
      "140\n",
      "135\n",
      "141\n",
      "132\n",
      "123\n",
      "123\n",
      "127\n",
      "135\n",
      "143\n",
      "150\n",
      "133\n",
      "138\n",
      "134\n",
      "End\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# 기준각도 반영\n",
    "\n",
    "# 발목 각도\n",
    "cap = cv2.VideoCapture('./video/측면1.mp4')\n",
    "ankle_fd_back = None\n",
    "cnt = 0\n",
    "\n",
    "#재생할 파일의 넓이와 높이\n",
    "width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "\n",
    "print(\"재생할 파일 넓이, 높이 : %d, %d\"%(width, height))\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "out = cv2.VideoWriter('output.avi', fourcc, 3.0, (int(width), int(height)))\n",
    "\n",
    "\n",
    "## Setup mediapipe instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            print(\"End\")\n",
    "            break\n",
    "        \n",
    "        # Recolor image to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "      \n",
    "        # Make detection\n",
    "        results = pose.process(image)\n",
    "    \n",
    "        # Recolor back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Extract landmarks\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            # 발목\n",
    "            # 좌표\n",
    "            knee = [landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].y]\n",
    "            ankle = [landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].y]\n",
    "            foot = [landmarks[mp_pose.PoseLandmark.RIGHT_FOOT_INDEX.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_FOOT_INDEX.value].y]\n",
    "            \n",
    "            # 각도\n",
    "            ankle_angle = calculate_angle(knee, ankle, foot)\n",
    "            print(ankle_angle)\n",
    "            \n",
    "#             # Visualize angle\n",
    "#             cv2.putText(image, str(ankle_angle), \n",
    "#                            tuple(np.multiply(ankle, [640, 480]).astype(int)), \n",
    "#                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA\n",
    "#                                 )\n",
    "            \n",
    "            # 각도 시각화\n",
    "#             cv2.rectangle(image, (0,0), (225,73), (245,117,16), -1)\n",
    "\n",
    "#             cv2.putText(image, 'Angle', (20,12), \n",
    "#                         cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1, cv2.LINE_AA)\n",
    "#             cv2.putText(image, str(ankle_angle), \n",
    "#                         (10,60), \n",
    "#                         cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            if ankle_angle > 112.3:\n",
    "                ankle_fd_back = \"good\"\n",
    "            if ankle_angle <= 112.3:\n",
    "                ankle_fd_back=\"bad\"\n",
    "                cnt = cnt + 1\n",
    "                       \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "#         cv2.rectangle(image, (255,0), (510,73), (245,117,16), -1)\n",
    "\n",
    "#         cv2.putText(image, 'Ankle', (350,12), \n",
    "#                     cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1, cv2.LINE_AA)\n",
    "#         cv2.putText(image, ankle_fd_back, \n",
    "#                     (350,60), \n",
    "#                     cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "        \n",
    "        \n",
    "        # Render detections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                mp_drawing.DrawingSpec(color=(255,0,0), thickness=2, circle_radius=2), \n",
    "                                mp_drawing.DrawingSpec(color=(255,144,30), thickness=2, circle_radius=2) \n",
    "                                 )\n",
    "        \n",
    "        if ankle_fd_back == 'bad':\n",
    "            if results.pose_landmarks:\n",
    "                # 왼쪽 어깨, 팔꿈치, 손목의 랜드마크 인덱스\n",
    "                right_ankle_landmarks = [mp_pose.PoseLandmark.RIGHT_KNEE,\n",
    "                                      mp_pose.PoseLandmark.RIGHT_ANKLE,\n",
    "                                      mp_pose.PoseLandmark.RIGHT_FOOT_INDEX]\n",
    "\n",
    "                # 왼팔의 점을 빨간색으로 그리기\n",
    "                for landmark in right_ankle_landmarks:\n",
    "                    landmark_px = results.pose_landmarks.landmark[landmark]\n",
    "                    x_px, y_px = int(landmark_px.x * image.shape[1]), int(landmark_px.y * image.shape[0])\n",
    "                    cv2.circle(image, (x_px, y_px), 5, (0, 0, 255), -1)\n",
    "\n",
    "                # 왼팔을 이어주는 선 그리기\n",
    "                cv2.line(image, (int(results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_KNEE].x * image.shape[1]),\n",
    "                                 int(results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_KNEE].y * image.shape[0])),\n",
    "                         (int(results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_ANKLE].x * image.shape[1]),\n",
    "                          int(results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_ANKLE].y * image.shape[0])), (0, 0, 255), 2)\n",
    "                cv2.line(image, (int(results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_ANKLE].x * image.shape[1]),\n",
    "                                 int(results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_ANKLE].y * image.shape[0])),\n",
    "                         (int(results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_FOOT_INDEX].x * image.shape[1]),\n",
    "                          int(results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_FOOT_INDEX].y * image.shape[0])), (0, 0, 255), 2)  \n",
    "        \n",
    "        cv2.imshow('Mediapipe Feed', image)\n",
    "        out.write(image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1f56fbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import Label, Frame, Button, Scale, HORIZONTAL, Canvas\n",
    "import cv2\n",
    "import PIL.Image, PIL.ImageTk\n",
    "\n",
    "class VideoPlayer:\n",
    "    def __init__(self, root, video_path):\n",
    "        self.root = root\n",
    "        self.root.title(\"Video Player\")\n",
    "        \n",
    "        self.video_path = video_path\n",
    "        self.video_cap = cv2.VideoCapture(video_path)\n",
    "        \n",
    "        # 비디오 원래 크기 가져오기\n",
    "        self.original_width = int(self.video_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        self.original_height = int(self.video_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "        # 비디오 크기를 줄이기 (예: 절반 크기로 설정)\n",
    "        self.width = self.original_width // 2\n",
    "        self.height = self.original_height // 2\n",
    "\n",
    "        # 재생 상태 변수\n",
    "        self.is_playing = True\n",
    "\n",
    "        # 전체 프레임을 만듭니다\n",
    "        self.main_frame = Frame(root)\n",
    "        self.main_frame.pack()\n",
    "\n",
    "        # 상단 텍스트 프레임을 만듭니다\n",
    "        self.top_frame = Frame(self.main_frame, width=self.width, height=50)\n",
    "        self.top_frame.pack()\n",
    "        self.top_label = Label(self.top_frame, text=\"인스텝 슈팅\", font=(\"Helvetica\", 16))\n",
    "        self.top_label.pack()\n",
    "\n",
    "        # 비디오 및 컨트롤 캔버스를 만듭니다\n",
    "        self.canvas = Canvas(self.main_frame, width=self.width, height=self.height)\n",
    "        self.canvas.pack()\n",
    "\n",
    "        # 재생/일시정지 버튼 추가\n",
    "        button_width = 8  # 버튼의 너비를 고정값으로 설정\n",
    "        button_height = 1  # 버튼의 높이를 고정값으로 설정\n",
    "        self.play_pause_button = Button(self.canvas, text=\"일시정지\", command=self.toggle_play_pause, width=button_width, height=button_height)\n",
    "        self.play_pause_button.place(x=self.width - 80, y=10)\n",
    "\n",
    "        # 슬라이더를 추가하여 재생 속도를 조절할 수 있게 합니다\n",
    "        self.speed_scale = Scale(self.canvas, from_=100, to=200,orient=HORIZONTAL, label=\"재생 속도\")\n",
    "        self.speed_scale.set(150)  # 기본 재생 속도를 15ms로 설정\n",
    "        self.speed_scale.place(x=self.width - 120, y=50)\n",
    "\n",
    "        # 기존 하단 텍스트 프레임\n",
    "        self.bottom_frame = Frame(self.main_frame, width=self.width, height=50)\n",
    "        self.bottom_frame.pack()\n",
    "        if cnt < 3:\n",
    "            self.bottom_label = Label(self.bottom_frame, text=\"Perfect\", font=(\"Helvetica\", 16), fg=\"blue\")  # 파란색으로 설정\n",
    "        elif cnt >= 3 and cnt <=5:\n",
    "            self.bottom_label = Label(self.bottom_frame, text=\"Good\", font=(\"Helvetica\", 16), fg=\"green\")\n",
    "        else:\n",
    "            self.bottom_label = Label(self.bottom_frame, text=\"Bad\", font=(\"Helvetica\", 16), fg=\"red\")\n",
    "        self.bottom_label.pack()\n",
    "\n",
    "        # 새로운 하단 텍스트 프레임\n",
    "        self.new_bottom_frame = Frame(self.main_frame, width=self.width, height=50)\n",
    "        self.new_bottom_frame.pack()\n",
    "        \n",
    "        if cnt < 3:\n",
    "            self.new_bottom_label = Label(self.new_bottom_frame, text=\"고칠 부분 없이 완벽해요\", font=(\"Helvetica\", 16))\n",
    "        elif cnt >= 3 and cnt <=5:\n",
    "            self.new_bottom_label = Label(self.new_bottom_frame, text=\"슈팅 임팩트 전후로 발목을 신경써서 슈팅해보세요\", font=(\"Helvetica\", 16))\n",
    "        else:\n",
    "            self.new_bottom_label = Label(self.new_bottom_frame, text=\"발목을 쭉 펴고 힘을 주어 고정하여 슈팅해보세요\", font=(\"Helvetica\", 16))\n",
    "\n",
    "        self.new_bottom_label.pack()\n",
    "\n",
    "        self.delay = 15\n",
    "        self.play_video()\n",
    "\n",
    "    def toggle_play_pause(self):\n",
    "        self.is_playing = not self.is_playing\n",
    "        if self.is_playing:\n",
    "            self.play_pause_button.config(text=\"일시정지\")\n",
    "            self.play_video()\n",
    "        else:\n",
    "            self.play_pause_button.config(text=\"재생\")\n",
    "\n",
    "    def play_video(self):\n",
    "        if self.is_playing:\n",
    "            ret, frame = self.video_cap.read()\n",
    "            if ret:\n",
    "                # 프레임 크기를 줄입니다\n",
    "                frame = cv2.resize(frame, (self.width, self.height))\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                img = PIL.ImageTk.PhotoImage(image=PIL.Image.fromarray(frame))\n",
    "                self.canvas.create_image(0, 0, anchor=tk.NW, image=img)\n",
    "                self.canvas.image = img\n",
    "                \n",
    "                # 재생 속도를 슬라이더 값으로 설정합니다\n",
    "                self.delay = self.speed_scale.get()\n",
    "                self.root.after(self.delay, self.play_video)\n",
    "            else:\n",
    "                self.video_cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "                self.play_video()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    video_path = \"output.avi\"  # 동영상 파일 경로 설정\n",
    "    player = VideoPlayer(root, video_path)\n",
    "    root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06695f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
